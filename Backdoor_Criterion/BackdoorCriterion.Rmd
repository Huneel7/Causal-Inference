---
title: "Backdoor Criterion"
output: pdf_document
---

<style type="text/css">

body{
   font-size: 20px;
}

h1.title {
  font-size: 25px;
  color: DarkRed;
}

h1 { /* Header 1 */
  font-size: 20px;
  color: DarkBlue;
}

</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE, message = FALSE}
library(dagitty)
library(ggdag)
library(dplyr)
library(ggplot2)
library(tidyverse)
```

# Definition (The Backdoor Criterion)

Given an ordered pair of variables (*X,Y*) in a directed acyclic graph *G*, a set of variables *Z* satisfies the backdoor criterion relative to (*X, Y*) if no node in *Z* is a descendant of *X*, and *Z* blocks every path between *X* and *Y* that contains an arrow into X.

# Causal Effect

If a set of variables Z satisfies the backdoor criterion for X and Y, then the causal effect of X on Y is given by the formula:

$P(Y=y \mid do(X=x))$ = $\sum_{z}^{} P(Y=y \mid X=x,Z= z)P(Z = z)$

Introducing regime indicator ($F_{X}$) which takes values in {do$(x^{'})$, idle (no intervention)} for proof and an example of graphical model, $G^{'}$. Note that a graphical model without $F_{X}$ is $G^{}$ and $G^{'} = G \bigcup${$F_{i}\rightarrow X_{i}$}.  

```{r, echo = FALSE, message = FALSE, fig.width=10, fig.height=3.2}
g <- dagitty('dag {
    Fx [pos="0,0"]
    X [pos="1,0"]
    Y [pos="2,0"]
    Z [pos="2,1"]
    Fx -> X -> Y 
    Z -> X 
    Z -> Y
}')

ggdag(g)+theme_dag_blank()
```

$\\$
$\\$
The conditonal probability, $P(x_{i} \mid pa(x_{i}, G^{'}))$, introduces the new parent set of Xi, $PA^{'}_{i} = PA_{i} \bigcup${$F_{i}$}

$\\$
$\\$

$P(x_{i} \mid pa(x_{i}, G^{'})) = \begin{cases} P(x_{i} \mid pa(x_{i}, G))\ \ \ \ \  if\ F_{i} = idle \\\\ 1\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ if\ F_{i} = do(x^{'}_{i}) \ and \ x_{i} = x^{'}_{i} \\\\ 0\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ if\ F_{i} = do(x^{'}_{i}) \ and \ x_{i} \neq x^{'}_{i} \end{cases}$

$\\$
$\\$

Now, we are ready for proof!

\newpage

# Proof for $P(y \mid do(x)) = \sum_{z}^{} P(y \mid z,x)P(z)$:
$P(y \mid do(x))$

$= \ P(y \mid F_{x} = do(x))$ 

$= \ \sum_{z}^{} P(y, z \mid F_{x} = do(x))$ 

$= \ \sum_{z}^{} P(y \mid z, F_{x} = do(x))P(z \mid F_{x} = do(x))$

$= \ \sum_{z}^{} P(y \mid z,x, F_{x} = do(x))P(z \mid F_{x} = do(x))$

$=^1 \sum_{z}^{} P(y \mid z,x, F_{x} = do(x))P(z)$

$=^2 \sum_{z}^{} P(y \mid z,x)P(z)$ 

(1) Parental Markov condition (local Markov condition):
A necessary and sufficient condition for a probability distribution P to be Markov relative a DAG G is that every variable be independent of all its nondescendants (in G), conditional on its parents. 

    By this theorem, $F_{x} \perp\!\!\!\perp Z$

(2) By backdoor condition, $F_{x} \ and \ Y$ are d-separated, conditional on Z and X $=>$ $F_{x} \perp\!\!\!\perp Y \mid Z,X$

# PA(X) always satisfies backdoor criterion:
$P(y \mid pa(x)) = \sum_{z}^{} P(y \mid pa(x),x)P(pa(x))$

# Backdoor Criterion Example 1:
```{r, echo = FALSE, message = FALSE, fig.width=4, fig.height=3.2}
set.seed(777)
dagify(y ~ x, x ~ z, w ~ z, y ~ w) %>%
  tidy_dagitty() %>%
  mutate(linetype = ifelse(name == "z", "dashed", "solid")) %>% 
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges(aes(edge_linetype = linetype), show.legend = FALSE) +
  geom_dag_point() +
  geom_dag_text() +
  theme_dag() 
```

Here, we want to estimate the effect of smoking cigarette (x) on lung function (y). Weight, w, is also measured and we know the type of jobs affect both weight and the choice to smoke cigarette. However, the study did not record the type of jobs. Though, z is not recorded, we can estimate $P(Y = y \mid do(X = x))$ using the backdoor criterion. Here, w is not a descendant of x and also blocks the backdoor path $x\ \leftarrow \ z\  \rightarrow \ w\  \rightarrow \ y$. 
Thus, $P(Y = y \mid do(X = x))$ = $\sum_{w}^{} P(Y=y \mid X=x,W=w)P(W = w)$

```{r, echo = FALSE, message = FALSE, fig.width=4, fig.height=3.2}
set.seed(777)
dagify(y ~ x, x ~ z, w ~ z, y ~ w) %>%
  tidy_dagitty() %>%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges() +
  geom_dag_point() +
  geom_dag_text() +
  theme_dag() 
```

Now assume z is observed as well as w. Then, blocking the backdoor path can be done by adjusting for either z or w. This is useful because the choice can be made depending on which variable is more convenient to measure. 

$P(Y = y \mid do(X = x))$ = $\sum_{w}^{} P(Y=y \mid X=x,W=w)P(W = w)$ = $\sum_{w}^{} P(Y=y \mid X=x,Z=z)P(Z = z)$

# Backdoor Criterion Example 2:
```{r, echo = FALSE, message = FALSE, fig.width=7, fig.height=3.5}
g3 <- dagitty('dag {
    Z [pos="-2,1"]
    T [pos="2.4,2"]
    X [pos="2.5,1"]
    Y [pos="3,1"]
    Z [pos="2,1"]
    W [pos="2.3,0"]
    U [pos="2.3,-1"]
    Z -> W -> U 
    X -> W 
    X -> Y
    T -> Z
    T -> Y
}')

ggdag(g3) + theme_dag_blank()
```

Here, we want to estimate the effect of X on Y for a specific value w of W. Though W is a collider and conditioning on W opens a path, T (not a descendant of X) can be used to block the spurious path $X\ \rightarrow \ W\ \leftarrow \ Z\  \leftrightarrow \ T\  \rightarrow \ Y$.

```{r, echo = FALSE, message = FALSE, fig.width=7, fig.height=3.5}
g3_2 <- dagitty('dag {
    Z [pos="-2,1"]
    T [pos="2.4,2"]
    X [pos="2.5,1"]
    Y [pos="3,1"]
    Z [pos="2,1"]
    W [pos="2.3,0"]
    U [pos="2.3,-1"]
    Z -> W -> U 
    X -> W 
    X -> Y
    T -> Z
    T -> Y
}')

control_for(g3_2, c("W", "T")) %>% 
  ggdag_adjust() +
  theme_dag() 
```

We can see the backdoor path is blocked when adjusting for W and T. 

Thus, $P(Y = y \mid do(X = x), W = w)$ = $\sum_{t}^{} P(Y=y \mid X=x,W=w, T=t)P(T = t \mid W = w)$

# Backdoor Criterion Example 3:
```{r, echo = FALSE, message = FALSE, fig.width=5, fig.height=3.3}
g4 <- dagitty('dag {
    L [pos="1,1"]
    X [pos="2,1"]
    Y [pos="3,1"]
    U1 [pos="0.9,2"]
    U2 [pos="0.9,0"]
    L -> X -> Y 
    X -> Y 
    U1 -> L 
    U1 -> Y
    U2 -> L
    U2 -> X
}')

ggdag(g4) + theme_dag_blank()
```

Here, we want to estimate the effect of X on Y. Conditioning on L would block the backdoor path,  $X\ \leftarrow \ L\   \leftarrow \ U_{1}\  \rightarrow \ Y$, but would simultaneously open a new backdoor path, $X\ \rightarrow \ U_{2}\ \rightarrow \ L\  \leftarrow \ U_{1}\  \rightarrow \ Y$. Namely, the attempt to block the confounding path brings about a selection bias. Here, A solution would be to measure either (i) a variable $L_{1}$ between $U_{1}$ and either A or Y, or (ii) a variable $L_{2}$ between $u_{2}$ and either A or L. 

# Example 3 Solution 1 ($L_{1}$ between $U_{1}$ and Y):
```{r, echo = FALSE, message = FALSE, fig.width=8, fig.height=3.3}
g4_2 <- dagitty('dag {
    L [pos="1,1"]
    L1 [pos="1.8,1.8"]
    X [pos="2,1"]
    Y [pos="3,1"]
    U1 [pos="0.9,2"]
    U2 [pos="0.9,0"]
    L -> X -> Y 
    X -> Y 
    U1 -> L 
    U1 -> L1 
    L1 -> Y
    U2 -> L
    U2 -> X
}')

control_for(g4_2, c("L1")) %>% 
  ggdag_adjust() +
  theme_dag() 
```

Adjusting for $L_{1}$ blocks the backdoor path.

Thus, $P(Y = y \mid do(X = x))$ = $\sum_{l_{1}}^{} P(Y=y \mid X=x,L_{1}=l_{1})P(L_{1}=l_{1})$

# Example 3 Solution 1 ($L_{1}$ between $U_{1}$ and X):
```{r, echo = FALSE, message = FALSE, fig.width=8, fig.height=3.3}
g4_3 <- dagitty('dag {
    L [pos="1,1"]
    L1 [pos="1.5,1.8"]
    X [pos="2,1"]
    Y [pos="3,1"]
    U1 [pos="0.9,2"]
    U2 [pos="0.9,0"]
    L -> X -> Y 
    X -> Y 
    U1 -> L 
    U1 -> L1 
    L1 -> X
    U2 -> L
    U2 -> X
}')

control_for(g4_3, NULL) %>%
  ggdag_adjust() + theme_dag() 
```
There is no backdoor path by adding $L_{1}$ variable.

Thus, $P(Y = y \mid do(X = x))$ = $P(Y=y \mid X=x)$

# Example 3 Solution 2 ($L_{2}$ between $U_{2}$ and X):
```{r, echo = FALSE, message = FALSE, fig.width=8, fig.height=3.3}
g4_4 <- dagitty('dag {
    L [pos="1,1"]
    X [pos="2,1"]
    Y [pos="3,1"]
    U1 [pos="0.9,2"]
    L2 [pos="1.5,0.2"]
    U2 [pos="0.9,0"]
    L -> X -> Y 
    X -> Y 
    U1 -> L 
    U1 -> Y 
    U2 -> L
    U2 -> L2
    L2 -> X
}')

control_for(g4_4, c("L", "L2")) %>% 
  ggdag_adjust() +
  theme_dag() 
```

Adjusting for L and L2 blocks the backdoor path.

Thus, $P(Y = y \mid do(X = x))$ = $\sum_{l,l_{2}}^{} P(Y=y \mid X=x, L=l,L_{2}=l_{2})P(L=l,L_{2}=l_{2})$

# Example 3 Solution 2 ($L_{2}$ between $U_{2}$ and L):
```{r, echo = FALSE, message = FALSE, fig.width=9, fig.height=5}
g4_5 <- dagitty('dag {
    L [pos="1,1"]
    X [pos="2,1"]
    Y [pos="3,1"]
    U1 [pos="0.9,2"]
    L2 [pos="1,0.3"]
    U2 [pos="0.9,-0.5"]
    L -> X -> Y 
    X -> Y 
    U1 -> L 
    U1 -> Y 
    U2 -> L2
    L2 -> L
    U2 -> X
}')

control_for(g4_5, c("L", "L2")) %>% 
  ggdag_adjust() +
  theme_dag() 
```

Adjusting for L and L2 blocks the backdoor path.

Thus, $P(Y = y \mid do(X = x))$ = $\sum_{l,l_{2}}^{} P(Y=y \mid X=x, L=l,L_{2}=l_{2})P(L=l,L_{2}=l_{2})$

\newpage

# Reference

Pearl, J., Glymour, M., &amp; Jewell, N. P. (2019). Causal inference in statistics a primer. Wiley. 
$\\$

Hern√°n MA, Robins JM (2020). Causal Inference: What If. Boca Raton: Chapman & Hall/CRC.


